functionality:
  namespace: "metrics"
  info:
    type: metrics
    type_info:
      label: Label
      summary: A metric to evaluate the performance of the inferred GRN
      description: |
        A metric to evaluate the performance of the inferred GRN
  arguments: 
    - name: --perturbation_data
      __merge__: file_perturbation_h5ad.yaml
      required: false
      direction: input
    - name: --prediction
      __merge__: file_prediction.yaml
      required: true
      direction: input
    - name: --score
      __merge__: file_score.yaml
      required: false
      direction: output
    - name: --reg_type
      type: string
      direction: input
      default: ridge
      description: name of regretion to use
      multiple: false
    - name: --subsample
      type: integer
      direction: input
      default: -2
      description: number of samples randomly drawn from perturbation data
    - name: --max_workers
      type: integer
      direction: input
      default: 4
    - name: --method_id 
      type: string 
      direction: input 
      required: false
      example: collectri
    - name: --tf_all
      type: file
      direction: input
      example: resources_test/prior/tf_all.csv
    - name: --apply_tf
      type: boolean 
      required: false
      default: true


      
  test_resources:
    - type: python_script
      path: /src/common/component_tests/run_and_check_output.py
    - path: /resources_test/grn-benchmark
      dest: resources_test/grn-benchmark
    - path: /resources_test/prior
      dest: resources_test/prior
